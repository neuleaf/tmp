{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.ones((2,3))\n",
    "print(a)\n",
    "np.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo/a:0\n",
      "foo/biases:0\n",
      "foo_1/c:0\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('foo') as foo:\n",
    "    a=tf.constant(0, name='a')\n",
    "    biases = tf.get_variable(shape=[512],initializer=tf.constant_initializer(0.0),  name='biases')\n",
    "    print(a.name,)\n",
    "    print(biases.name)\n",
    "with tf.variable_scope(foo, reuse=True):\n",
    "    c=tf.constant('2', name='c')\n",
    "    print(c.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
   "cell_type": "markdown",
   "metadata": {},
>>>>>>> ef346199a4e33353a3584a1147ee6043b8851fd1
   "source": [
    "## tf.nn.conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------case 2---------\n",
      "[[[[ 5.]\n",
      "   [ 5.]\n",
      "   [ 5.]]\n",
      "\n",
      "  [[ 5.]\n",
      "   [ 5.]\n",
      "   [ 5.]]\n",
      "\n",
      "  [[ 5.]\n",
      "   [ 5.]\n",
      "   [ 5.]]]]\n",
      "---------------------\n",
      "\n",
      "\n",
      "----------case 3---------\n",
      "[[[[ 45.]]]]\n",
      "---------------------\n",
      "\n",
      "\n",
      "----------case 4---------\n",
      "[[[[ 45.]\n",
      "   [ 45.]\n",
      "   [ 45.]]\n",
      "\n",
      "  [[ 45.]\n",
      "   [ 45.]\n",
      "   [ 45.]]\n",
      "\n",
      "  [[ 45.]\n",
      "   [ 45.]\n",
      "   [ 45.]]]]\n",
      "---------------------\n",
      "\n",
      "\n",
      "----------case 5---------\n",
      "[[[[ 20.]\n",
      "   [ 30.]\n",
      "   [ 30.]\n",
      "   [ 30.]\n",
      "   [ 20.]]\n",
      "\n",
      "  [[ 30.]\n",
      "   [ 45.]\n",
      "   [ 45.]\n",
      "   [ 45.]\n",
      "   [ 30.]]\n",
      "\n",
      "  [[ 30.]\n",
      "   [ 45.]\n",
      "   [ 45.]\n",
      "   [ 45.]\n",
      "   [ 30.]]\n",
      "\n",
      "  [[ 30.]\n",
      "   [ 45.]\n",
      "   [ 45.]\n",
      "   [ 45.]\n",
      "   [ 30.]]\n",
      "\n",
      "  [[ 20.]\n",
      "   [ 30.]\n",
      "   [ 30.]\n",
      "   [ 30.]\n",
      "   [ 20.]]]]\n",
      "---------------------\n",
      "\n",
      "\n",
      "----------case 6---------\n",
      "[[[[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]]]\n",
      "---------------------\n",
      "\n",
      "\n",
      "----------case 7---------\n",
      "[[[[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]]]\n",
      "---------------------\n",
      "\n",
      "\n",
      "----------case 8---------\n",
      "[[[[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]]\n",
      "\n",
      "\n",
      " [[[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]]\n",
      "\n",
      "\n",
      " [[[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]]\n",
      "\n",
      "\n",
      " [[[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]]]\n",
      "---------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)\n",
    "# 除去name参数用以指定该操作的name，与方法有关的一共五个参数：\n",
    "#\n",
    "# 第一个参数input：指需要做卷积的输入图像，它要求是一个Tensor，具有[batch, in_height, in_width, in_channels]这样的shape，具体含义是[训练时一个batch的图片数量, 图片高度, 图片宽度, 图像通道数]，注意这是一个4维的Tensor，要求类型为float32和float64其中之一\n",
    "#\n",
    "# 第二个参数filter：相当于CNN中的卷积核，它要求是一个Tensor，具有[filter_height, filter_width, in_channels, out_channels]这样的shape，具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]，要求类型与参数input相同，有一个地方需要注意，第三维in_channels，就是参数input的第四维\n",
    "#\n",
    "# 第三个参数strides：卷积时在图像每一维的步长，这是一个一维的向量，长度4\n",
    "#\n",
    "# 第四个参数padding：string类型的量，只能是\"SAME\",\"VALID\"其中之一，这个值决定了不同的卷积方式（后面会介绍）\n",
    "#\n",
    "# 第五个参数：use_cudnn_on_gpu:bool类型，是否使用cudnn加速，默认为true\n",
    "#\n",
    "# 结果返回一个Tensor，这个输出，就是我们常说的feature map\n",
    "\n",
    "oplist=[]\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 3, 3, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([1 ,1 , 5 ,1]))\n",
    "\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], padding='VALID')\n",
    "oplist.append([op2, \"case 2\"])\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 3, 3, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,1]))\n",
    "\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], padding='VALID')\n",
    "oplist.append([op2, \"case 3\"])\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,1]))\n",
    "\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], padding='VALID')\n",
    "oplist.append([op2, \"case 4\"])\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,1]))\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], padding='SAME')\n",
    "oplist.append([op2, \"case 5\"])\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,7]))\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1],  padding='SAME')\n",
    "oplist.append([op2, \"case 6\"])\n",
    "\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,7]))\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,2,2,1], padding='SAME')\n",
    "oplist.append([op2, \"case 7\"])\n",
    "\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([4, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,7]))\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,2,2,1],  padding='SAME')\n",
    "oplist.append([op2, \"case 8\"])\n",
    "\n",
    "with tf.Session() as a_sess:\n",
    "    a_sess.run(tf.global_variables_initializer())\n",
    "    for aop in oplist:\n",
    "        print(\"----------{}---------\".format(aop[1]))\n",
    "        print(a_sess.run(aop[0]))\n",
    "        print('---------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network variable_name test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=tf.constant(1)\n",
    "w=tf.constant(2)\n",
    "o=tf.multiply(x,w)\n",
    "o=tf.multiply(o,w)\n",
    "o=tf.multiply(o,w)\n",
    "o=tf.multiply(o,w)\n",
    "print o,w\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    r=sess.run(o)\n",
    "    print r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=tf.constant(1)\n",
    "b=tf.constant(2)\n",
    "o1=tf.multiply(a,b)\n",
    "o2=tf.multiply(o1,b)\n",
    "o3=tf.multiply(o2,b)\n",
    "with tf.Session() as sess:\n",
    "    # how many times does o1=tf.muliply run?\n",
    "    print(sess.run([o1,o2,o3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hello=tf.constant('hello')\n",
    "with tf.Graph().as_default():\n",
    "    hi=tf.constant(\"hi\")\n",
    "    print(hi.graph)\n",
    "    print(hello.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.5  3.5  3.5]\n",
      " [ 3.5  3.5  3.5]\n",
      " [ 5.5  5.5  5.5]]\n"
     ]
    }
   ],
   "source": [
    "# in this method, when resotre variables, the coresponding Variable should be declare first.\n",
    "# save\n",
    "with tf.variable_scope('train'):\n",
    "    w=tf.Variable([[1,1,1],[2,2,2]],dtype = tf.float32,name='w')\n",
    "    b = tf.Variable([0.5],dtype = tf.float32,name='b')\n",
    "x=tf.placeholder(shape=[3,2],dtype=tf.float32, name='input')\n",
    "y=tf.add(tf.matmul(x,w), b)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "saver=tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    m=np.array([[1,1],[1,1],[1,2]], dtype=np.float32)\n",
    "    print(sess.run(y, feed_dict={x:m}))\n",
    "    save_path=saver.save(sess, 'save/model01.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load! MUST firstly restart/refresh the kernel. Otherwise will got NAME INTERRUPTION.\n",
    "# declare variables with identical SHAPE,DTYPE,NAME. \n",
    "with tf.variable_scope('train'):\n",
    "    w=tf.Variable(tf.truncated_normal(shape=(2,3)), dtype=tf.float32, name='w')\n",
    "    b=tf.Variable(tf.truncated_normal(shape=(1,3)),dtype = tf.float32,name='b')\n",
    "    \n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"save/model01.ckpt\")\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-another example   -restore graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save. \n",
    "x1=tf.placeholder(tf.float32, [], name='x1')\n",
    "x2=tf.placeholder(tf.float32, [], name='x2')\n",
    "b=tf.Variable(2.0, name='bias')\n",
    "\n",
    "feed_dict={x1:4, x2:8}\n",
    "y1=tf.add(x1, x2)\n",
    "y2=tf.multiply(x1, x2)\n",
    "y3=tf.add(y2, b, name='output') # when restore, this name will be used. so define a name.\n",
    "# or \n",
    "# tf.add_to_collections('outputs',y3)\n",
    "# when restore, y3=tf.get_collection('outputs')[0]\n",
    "\n",
    "saver=tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run([y3, y2, y1], feed_dict))\n",
    "    saver.save(sess, 'save/model02.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# restore. Restart the kernel first.\n",
    "with tf.Session() as sess:\n",
    "    saver=tf.train.import_meta_graph('./save/model02.ckpt.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./save'))\n",
    "    \n",
    "    # test variable\n",
    "    print(sess.run('bias:0'))\n",
    "    # test graph\n",
    "    graph=tf.get_default_graph()\n",
    "    x1=graph.get_tensor_by_name(\"x1:0\")\n",
    "    x2=graph.get_tensor_by_name(\"x2:0\")\n",
    "    feed_dict={x1:3, x2:4}\n",
    "    \n",
    "    out=graph.get_tensor_by_name(\"output:0\")\n",
    "    # or out=graph.get_operation_by_name('output').outputs[0]\n",
    "    \n",
    "    print(sess.run(out, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch01\n",
      "ch02\n",
      "[1.0, 2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "class net:\n",
    "    def __init__(self):\n",
    "        self.input=tf.placeholder(tf.float32,[])\n",
    "        #self.forward(self.input)\n",
    "    def forward(self, img):\n",
    "        w=tf.Variable(1.0, name='w')\n",
    "        o1=tf.add(img, w)\n",
    "        o2=tf.add(o1, w)\n",
    "        print('ch01')\n",
    "        o3=tf.add(o2, w)\n",
    "        print('ch02')\n",
    "        return [o1,o2,o3]\n",
    "\n",
    "x=tf.placeholder(tf.float32,[])\n",
    "m=net()\n",
    "out=m.forward(x)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(out,feed_dict={x:0.0}))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py35(tf-gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
